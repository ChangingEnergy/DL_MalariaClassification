{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning Demo - Training a Malaria Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"TDS_Malaria.jpg\" alt=\"TDS_Malaria\" width=500 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Model Process\n",
    "\n",
    "- [Library Imports](#Imports)\n",
    "- [Image Preprocessing with OpenCV](#Preprocesing)\n",
    "- [Preparing and Normalizing the Dataset](#Normalization)\n",
    "- [Implementing the CNN Model Architecture](#CNNs)\n",
    "- [Model Evaluation](#Modelling)\n",
    "- [Inference](#Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Imports'></a>\n",
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 # imported from Open\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Preprocesing'></a>\n",
    "#### Image Preprocessing with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "img_dir=\"cell_images-1000\"  \n",
    "img_size=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def load_img_data(path):\n",
    "    image_files = glob.glob(os.path.join(path, \"Parasitized/*.png\")) + \\\n",
    "                  glob.glob(os.path.join(path, \"Uninfected/*.png\"))\n",
    "    X, y = [], []\n",
    "    for image_file in image_files:\n",
    "        # 0 for uninfected and 1 for infected\n",
    "        label = 0 if \"Uninfected\" in image_file else 1\n",
    "        # load the image in gray scale\n",
    "        img_arr = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        # resize the image to (70x70)\n",
    "        img_resized = cv2.resize(img_arr, (img_size, img_size))\n",
    "        X.append(img_resized)\n",
    "        y.append(label)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Normalization'></a>\n",
    "#### Preparing and Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "X, y = load_img_data(img_dir)\n",
    "# reshape to (n_samples, 70, 70, 1) (to fit the NN)\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "# scale pixels from the range [0, 255] to [0, 1] \n",
    "# to help the neural network learn much faster\n",
    "X = X / 255 \n",
    "\n",
    "# shuffle & split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "print(\"Total training samples:\", X_train.shape)\n",
    "print(\"Total validation samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='CNNs'></a>\n",
    "#### Implementing the CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model with 3 epochs, 64 batch size\n",
    "model.fit(X_train, np.array(y_train), batch_size=64, epochs=3, validation_split=0.2)\n",
    "# if you already trained the model, uncomment below and comment above\n",
    "# so you can only load the previously trained model\n",
    "# model.load_weights(\"malaria-cell-cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Modelling'></a>\n",
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, np.array(y_test), verbose=0)\n",
    "print(f\"Testing on {len(X_test)} images, the results are\\n Accuracy: {accuracy} | Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Inference'></a>\n",
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NB move two images from both classes (Parasitized and Uninfected) \n",
    "into a new (sub)folder called testing-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# testing some images\n",
    "uninfected_cell = \"cell_images/testing-samples/C1_thinF_IMG_20150604_104919_cell_123.png\"\n",
    "infected_cell = \"cell_images/testing-samples/C33P1thinF_IMG_20150619_121503a_cell_159.png\"\n",
    "\n",
    "_, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(plt.imread(uninfected_cell))\n",
    "ax[0].title.set_text(\"Uninfected Cell\")\n",
    "ax[1].imshow(plt.imread(infected_cell))\n",
    "ax[1].title.set_text(\"Parasitized Cell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load above images and perform preprocessing:\n",
    "img_arr_uninfected = cv2.imread(uninfected_cell, cv2.IMREAD_GRAYSCALE)\n",
    "img_arr_infected = cv2.imread(infected_cell, cv2.IMREAD_GRAYSCALE)\n",
    "# resize the images to (70x70)\n",
    "img_arr_uninfected = cv2.resize(img_arr_uninfected, (img_size, img_size))\n",
    "img_arr_infected = cv2.resize(img_arr_infected, (img_size, img_size))\n",
    "# scale to [0, 1]\n",
    "img_arr_infected = img_arr_infected / 255\n",
    "img_arr_uninfected = img_arr_uninfected / 255\n",
    "# reshape to fit the neural network dimensions\n",
    "# (changing shape from (70, 70) to (1, 70, 70, 1))\n",
    "img_arr_infected = img_arr_infected.reshape(1, *img_arr_infected.shape)\n",
    "img_arr_infected = np.expand_dims(img_arr_infected, axis=3)\n",
    "img_arr_uninfected = img_arr_uninfected.reshape(1, *img_arr_uninfected.shape)\n",
    "img_arr_uninfected = np.expand_dims(img_arr_uninfected, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# perform inference\n",
    "infected_result = model.predict(img_arr_infected)[0][0]\n",
    "uninfected_result = model.predict(img_arr_uninfected)[0][0]\n",
    "print(f\"Infected: {infected_result}\")\n",
    "print(f\"Uninfected: {uninfected_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN BELOW UNLESS TRAINING/TESTING IS EXTENDED TO LARGER DATASET\n",
    "# fromhttps://www.kaggle.com/iarunava/cell-images-for-detecting-malaria\n",
    "\n",
    "# save the model & weights\n",
    "# model.save(\"malaria-cell-cnn.h5\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "autolaunch": true,
   "theme": "solarized"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
